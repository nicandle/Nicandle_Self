# 20260129数据整理

---

## 1. ###孵化倾向强度多阶梯分析_spark.sql
```sql
-- 目标：分析孵化机会的倾向性（动力强度）多阶梯分布
-- 逻辑：
-- 1. 基础人群：当日有领取孵化行为的用户 (数据1：领取总用户数)
-- 2. 倾向性阶梯：在基础人群中，分别统计起孵化次数 >=3, >=4, >=5, >=6, >=7 的用户数及占比
-- 数据库：nvwa_cbt1, nvwa_cooked_cbt1

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt = '20260129'
      AND ip_region IN ('BR', 'ID')
),
claim_users as (
    -- 第二步：获取当日有领取行为的用户 (数据1基准)
    SELECT 
        account_id
    FROM nvwa_cbt1.PetClaim
    WHERE local_dt_srv >= '20260129'
    GROUP BY account_id
),
hatch_stats as (
    -- 第三步：统计这些用户的起孵化次数
    SELECT 
        account_id,
        count(*) as hatch_total_count
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260129'
    GROUP BY account_id
),
user_combined as (
    -- 第四步：合并数据，为每个领取玩家打上孵化阶梯标签
    SELECT 
        p.region,
        p.account_id,
        p.is_r2_flag,
        coalesce(h.hatch_total_count, 0) as hatch_count
    FROM player_base p
    INNER JOIN claim_users c ON p.account_id = c.account_id
    LEFT JOIN hatch_stats h ON p.account_id = h.account_id
),
thresholds as (
    -- 第五步：定义阶梯阈值（用于交叉连接生成表格结构）
    SELECT explode(array(3, 4, 5, 6, 7)) as min_hatch
)
-- 第六步：最终聚合统计
SELECT 
    u.region as `游戏大区`,
    t.min_hatch as `孵化次数阈值(>=N)`,
    count(distinct u.account_id) as `符合条件用户数(数据2)`,
    -- 计算占比：数据2 / 数据1 (该大区下所有领取用户的总数)
    concat(round(count(distinct u.account_id) * 100.0 / nullif(first(total_claim_users_in_region), 0), 2), '%') as `倾向强度占比`,
    sum(u.is_r2_flag) as `留存玩家数`,
    concat(round(sum(u.is_r2_flag) * 100.0 / nullif(count(distinct u.account_id), 0), 2), '%') as `次留率`
FROM (
    -- 预计算每个大区的总领取人数，避免在聚合时产生歧义
    -- 修复：Spark 不支持 count(distinct) 窗口函数，改用 size(collect_set())
    SELECT 
        *,
        size(collect_set(account_id) over(partition by region)) as total_claim_users_in_region
    FROM user_combined
) u
CROSS JOIN thresholds t
WHERE u.hatch_count >= t.min_hatch
GROUP BY u.region, t.min_hatch
ORDER BY u.region ASC, t.min_hatch ASC;
```

---

## 2. 孵化倾向强度分析_spark.sql
```sql
-- 目标：分析孵化机会的倾向性（动力强度）
-- 逻辑：
-- 1. 基础人群：当日有领取孵化行为的用户 (PetClaim)
-- 2. 倾向性指标：在基础人群中，起孵化次数 (PetCreateCustom) >= 2 的用户占比
-- 数据库：nvwa_cbt1, nvwa_cooked_cbt1

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
claim_users as (
    -- 第二步：获取当日有领取行为的用户 (数据1：领取孵化的当日用户数)
    SELECT 
        account_id,
        count(*) as claim_total_count
    FROM nvwa_cbt1.PetClaim
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
),
hatch_stats as (
    -- 第三步：统计这些用户的起孵化次数 (PetCreateCustom)
    SELECT 
        account_id,
        count(*) as hatch_total_count
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
)
-- 第四步：聚合统计
SELECT 
    p.region as `游戏大区`,
    count(distinct c.account_id) as `领取孵化总用户数(数据1)`,
    count(distinct case when h.hatch_total_count >= 3 then c.account_id end) as `起孵化大于等于3次用户数(数据2)`,
    concat(round(count(distinct case when h.hatch_total_count >= 3 then c.account_id end) * 100.0 / nullif(count(distinct c.account_id), 0), 2), '%') as `孵化倾向强度(数据2/数据1)`,
    -- 留存相关分析
    sum(case when h.hatch_total_count >= 3 then p.is_r2_flag else 0 end) as `高倾向留存玩家数`,
    concat(round(sum(case when h.hatch_total_count >= 3 then p.is_r2_flag else 0 end) * 100.0 / nullif(count(distinct case when h.hatch_total_count >= 3 then c.account_id end), 0), 2), '%') as `高倾向玩家次留率`
FROM player_base p
INNER JOIN claim_users c ON p.account_id = c.account_id
LEFT JOIN hatch_stats h ON p.account_id = h.account_id
GROUP BY 1
ORDER BY 1 ASC;
```

---

## 3. 孵化次数需求描述.md
# 孵化领取率需求描述

## 1. 基础信息
- **项目名称**: 孵化系统数据分析
- **数据库**: `nvwa_cbt1`
- **引擎要求**: Spark SQL

## 2. 核心需求
*(请在此补充具体需求，例如：)*
- 孵化领取率与留存玩家数/流失玩家数的关系，留存相关数值格式参考“建筑等级留存等级分析_spark”
- 单个用户PetCreateCustom日志数量开始孵化次数
- 单个用户PetClaim日志数量表示为孵化领取成功次数


## 3. 期望输出字段
查看流失玩家和留存玩家孵化领取率的分布图

---

## 4. 孵化系统深度分析需求文档.md
# 孵化系统深度分析需求文档

## 1. 基础信息
- **文档名称**: 孵化系统多维度留存与倾向分析
- **创建日期**: 2026-01-29
- **数据库**: `nvwa_cbt1`, `nvwa_cooked_cbt1`
- **引擎要求**: Spark SQL

## 2. 已完成分析模块
目前已根据需求生成了以下 SQL 分析工具：

### A. 基础留存分析
- **[建筑等级留存分析_spark.sql]**: 分析不同家园建筑等级（building_type=101）下的玩家分布及次留情况。
- **[领取次数留存分析_spark.sql]**: 统计玩家累计领取孵化奖励的次数与留存/流失的关系。

### B. 孵化倾向与动力分析
- **[孵化倾向强度多阶梯分析_spark.sql]**: 针对 0129 注册用户，分析其孵化次数阶梯（>=3, >=4...）的分布及倾向强度。
- **[家园等级与孵化次数留存对比_spark.sql]**: 交叉对比相同家园等级下，不同孵化次数档位的玩家留存差异。

### C. 特定玩家行为追踪
- **[特定玩家ID提取_家园1级孵化6次以上_spark.sql]**: 提取处于新手阶段（家园1级）但具有极高孵化积极性的玩家名单。
- **[特定玩家生命源质产销记录_带家园等级_spark.sql]**: 追踪特定账号在不同家园等级下，生命源质（Item ID: 4001001-4005001）的产销日志。

## 3. 后续待分析方向
- [ ] 孵化行为与付费转化的关联分析。
- [ ] 不同孵化类型（PetCreateCustom 中的参数）的效果对比。
- [ ] 玩家从获取孵化机会到实际执行孵化的漏斗转化。

---

## 5. 孵化领取率分析_spark.sql
-- 目标：统计不同【孵化次数】与【领取次数】组合下的玩家分布及留存情况
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎要求：Spark SQL

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        -- 留存标志处理：1为留存，0为流失
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
hatch_stats as (
    -- 第二步：统计每个玩家的孵化次数 (PetCreateCustom)
    SELECT 
        account_id,
        count(*) as hatch_count
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
),
claim_stats as (
    -- 第三步：统计每个玩家的领取次数 (PetClaim)
    SELECT 
        account_id,
        count(*) as claim_count
    FROM nvwa_cbt1.PetClaim
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
),
user_combined_stats as (
    -- 第四步：合并玩家的孵化与领取数据
    SELECT 
        p.region,
        p.account_id,
        p.is_r2_flag,
        coalesce(h.hatch_count, 0) as hatch_count,
        coalesce(c.claim_count, 0) as claim_count
    FROM player_base p
    LEFT JOIN hatch_stats h ON p.account_id = h.account_id
    LEFT JOIN claim_stats c ON p.account_id = c.account_id
)
-- 第五步：按【孵化次数】和【领取次数】的组合进行聚合统计
SELECT 
    region as `游戏大区`,
    hatch_count as `孵化次数`,
    claim_count as `领取次数`,
    count(distinct account_id) as `玩家总数`,
    sum(is_r2_flag) as `留存玩家数`,
    count(distinct account_id) - sum(is_r2_flag) as `流失玩家数`,
    round(sum(is_r2_flag) * 100.0 / nullif(count(distinct account_id), 0), 2) as `次留率(%)`
FROM user_combined_stats
GROUP BY 1, 2, 3
ORDER BY 1, 2 ASC, 3 ASC;

---

## 6. 家园等级与孵化次数留存对比_spark.sql
-- 目标：分析相同家园等级下，不同孵化次数玩家的留存对比
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎要求：Spark SQL

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
home_level_info as (
    -- 第二步：提取每个玩家的最高家园等级 (假设 building_type=101 代表家园核心建筑)
    SELECT 
        account_id,
        max(building_level) as home_level
    FROM nvwa_cbt1.homebuild
    WHERE local_dt_srv >= '20260127'
      AND building_type = 101
    GROUP BY account_id
),
hatch_stats as (
    -- 第三步：统计每个玩家的孵化次数 (PetCreateCustom) 并分档
    SELECT 
        account_id,
        count(*) as raw_hatch_count,
        case 
            when count(*) = 1 then '1次'
            when count(*) = 2 then '2次'
            when count(*) = 3 then '3次'
            when count(*) = 4 then '4次'
            when count(*) = 5 then '5次'
            when count(*) >= 6 then '6次+'
            else '0次'
        end as hatch_tag
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
)
-- 第四步：聚合统计相同家园等级下，不同孵化档位的留存表现
SELECT 
    p.region as `游戏大区`,
    coalesce(hl.home_level, 1) as `家园等级`,
    coalesce(hs.hatch_tag, '0次') as `孵化次数档位`,
    count(distinct p.account_id) as `玩家总数`,
    sum(p.is_r2_flag) as `留存玩家数`,
    count(distinct p.account_id) - sum(p.is_r2_flag) as `流失玩家数`,
    concat(round(sum(p.is_r2_flag) * 100.0 / nullif(count(distinct p.account_id), 0), 2), '%') as `次留率`
FROM player_base p
LEFT JOIN home_level_info hl ON p.account_id = hl.account_id
LEFT JOIN hatch_stats hs ON p.account_id = hs.account_id
GROUP BY 1, 2, 3
ORDER BY 1, 2 ASC, 3 ASC;

---

## 7. 建筑等级留存分析_spark.sql
-- 目标：分析 building_type=101 的建筑等级分布及其对应的玩家留存情况
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎：Spark SQL 存档版
-- 筛选条件：注册日期 20260127~20260128，IP 区域为 BR 或 ID

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        local_dt,
        region,
        account_id,
        -- Spark 兼容性处理：转换为数字 1 或 0
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
building_log as (
    -- 第二步：提取这些玩家关于 101 建筑的最高等级记录
    SELECT 
        account_id,
        max(building_level) as max_level
    FROM nvwa_cbt1.homebuild
    WHERE local_dt_srv >= '20260127' 
      AND building_type = 101
    GROUP BY account_id
)
-- 第三步：以玩家底表为主，关联等级信息并聚合统计
-- Spark SQL 使用反引号 ` 来引用中文列名
SELECT 
    t1.region as `游戏大区`,
    coalesce(t2.max_level, 1) as `建筑等级`, 
    count(distinct t1.account_id) as `该等级玩家总数`,
    sum(t1.is_r2_flag) as `留存玩家数`,
    count(distinct t1.account_id) - sum(t1.is_r2_flag) as `流失玩家数`,
    round(sum(t1.is_r2_flag) * 100.0 / nullif(count(distinct t1.account_id), 0), 2) as `次留率(%)`
FROM player_base t1
LEFT JOIN building_log t2 ON t1.account_id = t2.account_id
GROUP BY t1.region, coalesce(t2.max_level, 1)
ORDER BY t1.region, `建筑等级` ASC;

---

## 8. 建筑等级留存分析.sql
-- 目标：分析 building_type=101 的建筑等级分布及其对应的玩家留存情况
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎：Trino (Presto) 终极修复版
-- 核心策略：彻底移除 = 1 这种 bigint 比较，改用字符串比较，并对 SUM 结果进行显式转换

with player_base as (
    -- 第一步：获取目标注册玩家底表
    SELECT 
        local_dt,
        region,
        account_id,
        -- 彻底隔离类型：将 is_r2 转换为字符串后再进行字符串比较，返回数字
        case 
            when cast(is_r2 as varchar) = '1' or cast(is_r2 as varchar) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
building_log as (
    -- 第二步：提取最高等级
    SELECT 
        account_id,
        max(building_level) as max_level
    FROM nvwa_cbt1.homebuild
    WHERE local_dt_srv >= '20260127' 
      AND building_type = 101
    GROUP BY account_id
)
-- 第三步：聚合统计
-- 关键：Trino 在处理 SUM 和 COUNT 混合计算时，有时会因为别名引用触发类型推导错误
-- 我们在 GROUP BY 中显式写出所有表达式，并确保计算中不出现隐式转换
SELECT 
    t1.region as "游戏大区",
    coalesce(t2.max_level, 1) as "建筑等级", 
    count(distinct t1.account_id) as "该等级玩家总数",
    -- 使用 sum 统计处理好的数字标志位
    sum(t1.is_r2_flag) as "留存玩家数",
    -- 显式计算流失人数
    count(distinct t1.account_id) - sum(t1.is_r2_flag) as "流失玩家数",
    -- 计算留存率：确保分子分母都是浮点数或显式转换
    round(cast(sum(t1.is_r2_flag) as double) * 100.0 / cast(nullif(count(distinct t1.account_id), 0) as double), 2) as "次留率(%)"
FROM player_base t1
LEFT JOIN building_log t2 ON t1.account_id = t2.account_id
GROUP BY t1.region, coalesce(t2.max_level, 1)
ORDER BY t1.region, "建筑等级" ASC;

---

## 9. 次留.sql
with avg_ping_fps as (
        -- 第一步：计算每个用户每天的平均网络指标（延迟和帧率）
        SELECT
            local_dt_srv as local_dt, -- 服务器本地日期
            account_id,               -- 玩家账号ID
            avg(ping) as avg_ping,    -- 计算当日平均延迟(Ping)
            avg(fps) as avg_fps       -- 计算当日平均帧率(FPS)
        FROM nvwa_cbt1.GameHeartbeat  -- 来源：游戏心跳原始日志表
        WHERE local_dt_srv  BETWEEN '20260127' AND '20260129' -- 筛选时间范围
        GROUP BY 1, 2                 -- 按日期和账号分组
    ),
    avg_ping_tag as (
        -- 第二步：将平均延迟数值转化为区间标签，方便后续按网络质量分类统计
        SELECT
            local_dt,
            account_id,
            case when avg_ping >= 0 and avg_ping < 50 then '[0-50)'
             when avg_ping >= 50 and avg_ping < 100 then '[50-100)'
             when avg_ping >= 100 and avg_ping < 150 then '[100-150)'
             when avg_ping >= 150 and avg_ping < 200 then '[150-200)'
             when avg_ping >= 200 and avg_ping < 250 then '[200-250)'
             when avg_ping >= 250 and avg_ping < 300 then '[250-300)'
             when avg_ping >= 300 and avg_ping < 350 then '[300-350)'
             when avg_ping >= 350 and avg_ping < 400 then '[350-400)'
             when avg_ping >= 400 and avg_ping < 450 then '[400-450)'
             when avg_ping >= 450 and avg_ping < 500 then '[450-500)'
             when avg_ping >= 500 and avg_ping < 550 then '[500-550)'
             when avg_ping >= 550 and avg_ping < 600 then '[550-600)'
             when avg_ping >= 600  then '[600,+∞)'
             end as avg_ping_tag      -- 延迟区间标签
        FROM avg_ping_fps
    ),
    retention_day as (
        -- 第三步：提取用户基础留存数据（预计算好的留存标志位）
        SELECT 
            local_dt
            ,region                   -- 游戏大区
            ,ip_region                -- IP所属地理位置
            ,account_id
            ,is_r2                    -- 次日留存标志（1为留存，0为未留存）
            ,is_r3                    -- 3日留存标志
            ,is_r4                    -- 4日留存标志
            ,is_r5                    -- 5日留存标志
            ,is_r6                    -- 6日留存标志
            ,is_r7                    -- 7日留存标志
            ,is_r14                   -- 14日留存标志
            ,is_r30                   -- 30日留存标志
        FROM {cooked_db}.dws_user_register_account_retention_d_i -- 来源：用户注册留存日增量表
        WHERE local_dt in (
            '20260129',
            '20260127','20260128'
        ))
            -- 第四步：最终聚合统计，计算不同维度下的留存人数
            SELECT 
            string(to_date(t1.local_dt, 'yyyyMMdd')) as local_dt -- 格式化日期
            ,coalesce(t1.region,'Unknown') as region             -- 填充大区空值
            ,coalesce(t1.ip_region,'Unknown') as ip_region       -- 填充IP地区空值
            ,coalesce(t2.avg_ping_tag,'Unknown') as avg_ping_tag -- 填充延迟标签空值（无心跳数据的用户）
            ,count(distinct t1.account_id) as new_user           -- 统计当日新增用户总数
            -- 使用条件计数法统计各阶段留存人数
            ,count(distinct case when t1.is_r2 = 1 then t1.account_id end) as r2   -- 次日留存数
            ,count(distinct case when t1.is_r3 = 1 then t1.account_id end) as r3   -- 3日留存数
            ,count(distinct case when t1.is_r4 = 1 then t1.account_id end) as r4   -- 4日留存数
            ,count(distinct case when t1.is_r5 = 1 then t1.account_id end) as r5   -- 5日留存数
            ,count(distinct case when t1.is_r6 = 1 then t1.account_id end) as r6   -- 6日留存数
            ,count(distinct case when t1.is_r7 = 1 then t1.account_id end) as r7   -- 7日留存数
            ,count(distinct case when t1.is_r14 = 1 then t1.account_id end) as r14 -- 14日留存数
            ,count(distinct case when t1.is_r30 = 1 then t1.account_id end) as r30 -- 30日留存数
        FROM retention_day t1 LEFT JOIN avg_ping_tag t2 ON t1.account_id = t2.account_id 
        and t1.local_dt = t2.local_dt
        GROUP BY 1, 2, 3, 4

---

## 10. 特定孵化领取条件留存分析_spark.sql
-- 目标：统计【至少有1次领取记录】且【总孵化次数 >= 2】的玩家留存情况
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎要求：Spark SQL

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        -- 留存标志处理：1为留存，0为流失
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
hatch_stats as (
    -- 第二步：统计每个玩家的孵化次数 (PetCreateCustom)
    SELECT 
        account_id,
        count(*) as hatch_count
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
    HAVING count(*) >= 2 -- 筛选总孵化次数 >= 2 的玩家
),
claim_stats as (
    -- 第三步：统计每个玩家的领取次数 (PetClaim)
    SELECT 
        account_id,
        count(*) as claim_count
    FROM nvwa_cbt1.PetClaim
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
    HAVING count(*) >= 1 -- 筛选至少有 1 次领取记录的玩家
)
-- 第四步：聚合统计符合条件的玩家留存表现
SELECT 
    p.region as `游戏大区`,
    count(distinct p.account_id) as `符合条件玩家总数`,
    sum(p.is_r2_flag) as `留存玩家数`,
    count(distinct p.account_id) - sum(p.is_r2_flag) as `流失玩家数`,
    concat(round(sum(p.is_r2_flag) * 100.0 / nullif(count(distinct p.account_id), 0), 2), '%') as `次留率`
FROM player_base p
INNER JOIN hatch_stats h ON p.account_id = h.account_id
INNER JOIN claim_stats c ON p.account_id = c.account_id
GROUP BY 1
ORDER BY 1 ASC;

---

## 11. 特定玩家ID提取_家园1级孵化6次以上_spark.sql
-- 目标：提取家园等级为 1 且孵化次数大于等于 6 次的玩家 ID 列表
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎要求：Spark SQL

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
home_level_info as (
    -- 第二步：提取每个玩家的最高家园等级 (building_type=101)
    SELECT 
        account_id,
        max(building_level) as home_level
    FROM nvwa_cbt1.homebuild
    WHERE local_dt_srv >= '20260127'
      AND building_type = 101
    GROUP BY account_id
),
hatch_stats as (
    -- 第三步：统计每个玩家的孵化次数 (PetCreateCustom)
    SELECT 
        account_id,
        count(*) as hatch_count
    FROM nvwa_cbt1.PetCreateCustom
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
    HAVING count(*) >= 6 -- 筛选孵化次数 6 次及以上的玩家
)
-- 第四步：关联并筛选家园等级为 1 的玩家
SELECT 
    p.region as `游戏大区`,
    p.account_id as `玩家ID`,
    coalesce(hl.home_level, 1) as `家园等级`,
    hs.hatch_count as `孵化次数`
FROM player_base p
INNER JOIN hatch_stats hs ON p.account_id = hs.account_id
LEFT JOIN home_level_info hl ON p.account_id = hl.account_id
WHERE coalesce(hl.home_level, 1) = 1 -- 筛选家园等级为 1 的玩家
ORDER BY p.region, hs.hatch_count DESC;

---

## 12. 特定玩家生命源质产销记录_spark.sql
-- 目标：查看特定玩家 ID 的生命源质（Item ID 列表）产销记录
-- 数据库：nvwa_cbt1
-- 日志表：exchangeitems
-- 引擎要求：Spark SQL

SELECT 
    account_id as `账号ID`,
    reason as `原因值(reason)`,
    sub_reason as `子原因值(sub_reason)`,
    local_dt_srv as `日期`,
    -- 展开结构体以查看具体的 item_id 和数量（可选，方便核对）
    item_change
FROM nvwa_cbt1.exchangeitems
-- 针对特定玩家 ID 进行筛选
WHERE account_id IN (10000635, 10000014, 10000077, 10000396, 10000055)
-- 筛选包含生命源质相关 Item ID 的记录
AND (
    array_contains(transform(item_change, x -> x.item_id), 4001001)
    OR array_contains(transform(item_change, x -> x.item_id), 4002001)
    OR array_contains(transform(item_change, x -> x.item_id), 4003001)
    OR array_contains(transform(item_change, x -> x.item_id), 4004001)
    OR array_contains(transform(item_change, x -> x.item_id), 4005001)
)
ORDER BY account_id, local_dt_srv ASC;

---

## 13. 特定玩家生命源质产销记录_带家园等级_spark.sql
-- 目标：查看特定玩家 ID 的生命源质产销记录，并关联其家园等级
-- 逻辑：1. 锁定账号 -> 2. 关联家园等级 (building_type=101) -> 3. 筛选特定物品日志

with target_users as (
    -- 第一步：定义目标账号列表
    SELECT explode(array(10000635, 10000014, 10000077, 10000396, 10000055)) as account_id
),
home_level_info as (
    -- 第二步：提取这些玩家的最高家园等级 (building_type=101)
    SELECT 
        account_id,
        max(building_level) as home_level
    FROM nvwa_cbt1.homebuild
    WHERE account_id IN (10000635, 10000014, 10000077, 10000396, 10000055)
      AND building_type = 101
    GROUP BY account_id
),
target_logs as (
    -- 第三步：获取这些账号的所有 exchangeitems 日志
    SELECT *
    FROM nvwa_cbt1.exchangeitems
    WHERE account_id IN (10000635, 10000014, 10000077, 10000396, 10000055)
)
-- 第四步：关联家园等级并筛选符合物品 ID 标准的记录
SELECT 
    l.account_id as `账号ID`,
    coalesce(h.home_level, 1) as `家园等级`, -- 无日志则默认为初始1级
    l.reason as `原因值(reason)`,
    l.sub_reason as `子原因值(sub_reason)`,
    l.local_dt_srv as `日期`,
    l.item_change
FROM target_logs l
LEFT JOIN home_level_info h ON l.account_id = h.account_id
WHERE (
    array_contains(transform(l.item_change, x -> x.item_id), 4001001)
    OR array_contains(transform(l.item_change, x -> x.item_id), 4002001)
    OR array_contains(transform(l.item_change, x -> x.item_id), 4003001)
    OR array_contains(transform(l.item_change, x -> x.item_id), 4004001)
    OR array_contains(transform(l.item_change, x -> x.item_id), 4005001)
)
ORDER BY l.account_id, l.local_dt_srv ASC;

---

## 14. 特定账号.md
# 新建需求文档

## 1. 基础信息
- **文档名称**: [请输入需求名称]
- **创建日期**: 2026-01-29
- **数据库**: `nvwa_cbt1`
- **引擎要求**: Spark SQL

## 2. 详细需求描述
查看这些ID玩家的生命源质产销记录
10000635，10000014，10000077，10000396，10000055

日志：exchangeitems
筛选字段：结构体item_change中item_id包含(10000031,
10000032,
10000033,
10000034,
10000035,
10000036,
10000041,
10000042,
10000043,
10000044,
10000045,
10000046)的日志记录

## 3. 期望输出
-账号id
-该条日志的中的reason字段值
-该条日志的中的sub_reason字段值

---

## 15. 示例格式.md
(文件为空)

---

## 16. 获取孵化机会的动力强度.md
# 获取孵化机会的动力强度分析需求

## 1. 基础信息
- **项目名称**: 孵化机会倾向分析
- **数据库**: `nvwa_cbt1`
- **引擎要求**: Spark SQL

## 2. 核心逻辑 definition
数据1：领取孵化的当日用户数
数据2：数据1这些用户中，起孵化次数 ≥2 的用户数

- 单个用户PetCreateCustom日志数量开始孵化次数
- 单个用户PetClaim日志数量表示为孵化领取成功次数

---

## 17. 领取次数留存分析_spark.sql
-- 目标：统计不同【领取次数】下的玩家分布及留存情况（忽略孵化次数）
-- 数据库：nvwa_cbt1 (原始日志), nvwa_cooked_cbt1 (留存底表)
-- 引擎要求：Spark SQL

with player_base as (
    -- 第一步：获取目标注册玩家底表（27-28号注册，且在指定地区）
    SELECT 
        region,
        account_id,
        -- 留存标志处理：1为留存，0为流失
        case 
            when cast(is_r2 as string) = '1' or cast(is_r2 as string) = 'true' then 1 
            else 0 
        end as is_r2_flag
    FROM nvwa_cooked_cbt1.dws_user_register_account_retention_d_i
    WHERE local_dt BETWEEN '20260127' AND '20260128'
      AND ip_region IN ('BR', 'ID')
),
claim_stats as (
    -- 第二步：统计每个玩家的累计领取次数 (PetClaim)
    SELECT 
        account_id,
        count(*) as claim_count
    FROM nvwa_cbt1.PetClaim
    WHERE local_dt_srv >= '20260127'
    GROUP BY account_id
)
-- 第三步：聚合统计不同领取次数下的留存表现
SELECT 
    p.region as `游戏大区`,
    coalesce(c.claim_count, 0) as `领取次数`,
    count(distinct p.account_id) as `玩家总数`,
    sum(p.is_r2_flag) as `留存玩家数`,
    count(distinct p.account_id) - sum(p.is_r2_flag) as `流失玩家数`,
    concat(round(sum(p.is_r2_flag) * 100.0 / nullif(count(distinct p.account_id), 0), 2), '%') as `次留率`,
    concat(round(sum(p.is_r2_flag) * 100.0 / nullif(sum(count(distinct p.account_id)) over(partition by p.region), 0), 2), '%') as `留存玩家占总玩家比例`
FROM player_base p
LEFT JOIN claim_stats c ON p.account_id = c.account_id
GROUP BY 1, 2
ORDER BY 1, 2 ASC;
